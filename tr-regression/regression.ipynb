{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from sklearn.metrics import r2_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "# df = pd.read_csv('../output/teacher-report/teacher_report_gyor.csv')\n",
    "df = pd.read_csv('../generate-tr/final_df_gyor.csv')\n",
    "with open('../data/moby/jsons/session_to_difficulty_metrics.json') as f:\n",
    "    session_to_difficulty_metrics = json.load(f)\n",
    "with open('../data/moby/jsons/session_to_acc_zscore.json') as f:\n",
    "    session_to_acc_zscore = json.load(f)\n",
    "with open('../data/moby/jsons/session_to_wcpm_zscore.json') as f:\n",
    "    session_to_wcpm_zscore = json.load(f)\n",
    "with open('../data/moby/jsons/session_to_acc_zscore_by_grade.json') as f:\n",
    "    session_to_acc_zscore_by_grade = json.load(f)\n",
    "with open('../data/moby/jsons/session_to_wcpm_zscore_by_grade.json') as f:\n",
    "    session_to_wcpm_zscore_by_grade = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "design = pd.read_csv('data/all_sessions_only_session_scores.csv')\n",
    "\n",
    "wcpm_zscore_column = [session_to_wcpm_zscore[str(session)] for session in design.Session]\n",
    "acc_zscore_column = [session_to_acc_zscore[str(session)] for session in design.Session]\n",
    "wcpm_zscore_by_grade_column = [session_to_wcpm_zscore_by_grade[str(session)] for session in design.Session]\n",
    "acc_zscore_by_grade_column = [session_to_acc_zscore_by_grade[str(session)] for session in design.Session]\n",
    "\n",
    "design['WCPM_zscore'] = wcpm_zscore_column\n",
    "design['Acc_zscore'] = acc_zscore_column\n",
    "design['WCPM_zscore_by_grade'] = wcpm_zscore_by_grade_column\n",
    "design['Acc_zscore_by_grade'] = acc_zscore_by_grade_column\n",
    "\n",
    "design = design.sort_values(by='Session').set_index('Session')\n",
    "df = df.sort_values(by='Session').set_index('Session')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matrix = design.join(df, on='Session').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlevel_numeric_column = []\n",
    "form_numeric_column = []\n",
    "mlevel_form_diff_column = []\n",
    "text_is_above_level_column = []\n",
    "\n",
    "for idx, row in full_matrix.iterrows():\n",
    "    session = str(int(row.Session))\n",
    "    difficulty_metrics = session_to_difficulty_metrics[session]\n",
    "    \n",
    "    mlevel_numeric_column.append(difficulty_metrics['mlevel_numeric'])\n",
    "    form_numeric_column.append(difficulty_metrics['form_numeric'])\n",
    "    mlevel_form_diff_column.append(difficulty_metrics['mlevel_form_diff'])\n",
    "    text_is_above_level_column.append(difficulty_metrics['text_is_above_level'])\n",
    "\n",
    "full_matrix['mlevel_numeric'] = mlevel_numeric_column\n",
    "full_matrix['form_numeric'] = form_numeric_column\n",
    "full_matrix['mlevel_form_diff'] = mlevel_form_diff_column\n",
    "full_matrix['text_is_above_level'] = text_is_above_level_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_matrix.to_csv('data/all_sessions_with_session_and_difficulty_scores.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Session', 'WCPM', 'Acc', 'Comp', 'Exp', 'level', 'WCPM_zscore',\n",
       "       'Acc_zscore', 'WCPM_zscore_by_grade', 'Acc_zscore_by_grade', 'gyorB',\n",
       "       'gyorC', 'gyorE', 'gyorF', 'gyorG', 'gyorH', 'gyorJ', 'gyorK', 'gyorL',\n",
       "       'gyorM', 'gyorN', 'gyorO', 'gyorP', 'gyorQ', 'mlevel_numeric',\n",
       "       'form_numeric', 'mlevel_form_diff', 'text_is_above_level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_predictions(predictions,\n",
    "                           cutoffs=['value < .5',\n",
    "                                    '.5 <= value < 1.5',\n",
    "                                    '1.5 <= value < 2.5',\n",
    "                                    '2.5 <= value']):\n",
    "    discretized = []\n",
    "    for value in predictions:\n",
    "        for idx, formula in enumerate(cutoffs):\n",
    "            if eval(formula):\n",
    "                discretized.append(idx)\n",
    "    assert len(discretized) == len(predictions)\n",
    "    return discretized\n",
    "    \n",
    "\n",
    "def run_regressor(matrix, feature_cols=[], col_to_predict=''):\n",
    "    X = matrix[feature_cols]\n",
    "    y = matrix[col_to_predict]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    print('Weights: ' + ', '.join(['{:.2f}'.format(x) for x in reg.coef_]))\n",
    "    \n",
    "    y_pred = reg.predict(X_test)    \n",
    "    y_pred_discretized = discretize_predictions(y_pred)\n",
    "    \n",
    "    conf_mat = ConfusionMatrix(y_test, y_pred_discretized)\n",
    "    \n",
    "    print('R2 (discretized): {:.3f}'.format(r2_score(y_test, y_pred_discretized)))\n",
    "    print('R2 (continuous):  {:.3f}'.format(r2_score(y_test, y_pred)))\n",
    "    \n",
    "    print('QWK: {:.3f}'.format(cohen_kappa_score(y_test, y_pred_discretized, weights=\"quadratic\")))\n",
    "    \n",
    "    print(str(conf_mat))\n",
    "    \n",
    "    accuracy = sum(1 for x, y in zip(y_test, y_pred_discretized) if x == y) / len(y_test)\n",
    "    print('Raw accuracy: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: 0.00, 8.79, 0.05, 0.51, -0.18, 0.76, -0.48, -0.45, 0.09, 0.05, 0.01, 0.04, -0.24\n",
      "R2 (discretized): 0.509\n",
      "R2 (continuous):  0.503\n",
      "QWK: 0.687\n",
      "  |   0   1   2   3   4   5   6 |\n",
      "--+-----------------------------+\n",
      "0 | <11> 31  12   .   .   .   . |\n",
      "1 |   2  <9> 18   4   .   .   . |\n",
      "2 |   .   7 <39> 15   .   .   . |\n",
      "3 |   .   7  56<154>  .   .   . |\n",
      "4 |   .   .   .   .  <.>  .   . |\n",
      "5 |   .   .   .   .   .  <.>  . |\n",
      "6 |   .   .   .   .   .   .  <.>|\n",
      "--+-----------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Raw accuracy: 0.584\n"
     ]
    }
   ],
   "source": [
    "feature_cols=[\n",
    "    'WCPM',\n",
    "    'Acc',\n",
    "    'Comp',\n",
    "    'Exp',\n",
    "    'level',\n",
    "    'WCPM_zscore',\n",
    "    'Acc_zscore',\n",
    "    'WCPM_zscore_by_grade',\n",
    "    'Acc_zscore_by_grade',\n",
    "    'mlevel_numeric',\n",
    "    'form_numeric',\n",
    "    'mlevel_form_diff',\n",
    "    'text_is_above_level',\n",
    "]\n",
    "\n",
    "run_regressor(full_matrix, feature_cols=feature_cols, col_to_predict='gyorJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: 0.01, 7.45, 0.03, 0.59, -0.14, 0.40, -0.33, -0.11, -0.16, 0.03, 0.02, 0.01, -0.15\n",
      "R2 (discretized): 0.661\n",
      "R2 (continuous):  0.707\n",
      "QWK: 0.804\n",
      "  |   0   1   2   3   4   5   6 |\n",
      "--+-----------------------------+\n",
      "0 | <20> 25   1   .   .   .   . |\n",
      "1 |   . <24> 20   1   .   .   . |\n",
      "2 |   2  12 <68>  8   .   .   . |\n",
      "3 |   .   4  41<139>  .   .   . |\n",
      "4 |   .   .   .   .  <.>  .   . |\n",
      "5 |   .   .   .   .   .  <.>  . |\n",
      "6 |   .   .   .   .   .   .  <.>|\n",
      "--+-----------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Raw accuracy: 0.688\n"
     ]
    }
   ],
   "source": [
    "run_regressor(full_matrix, feature_cols=feature_cols, col_to_predict='gyorL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_2_matrix = full_matrix.loc[(full_matrix.form_numeric <= 11) & (full_matrix.form_numeric >= 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/moby/jsons/session_to_difficulty_metrics.json') as f:\n",
    "    session_to_difficulty_metrics = json.load(f)\n",
    "\n",
    "difficulty_metrics_names = list(session_to_difficulty_metrics[list(session_to_difficulty_metrics.keys())[0]].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlevel_numeric', 'form_numeric', 'mlevel_form_diff', 'text_is_above_level']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difficulty_metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mlevel_numeric': 6, 'form_numeric': 9, 'mlevel_form_diff': -3, 'text_is_above_level': 0}\n"
     ]
    }
   ],
   "source": [
    "new_difficulty_metrics_columns = [[] for metric in difficulty_metrics_names]\n",
    "for idx, row in grade_2_matrix.iterrows():\n",
    "    session = str(int(row.Session))\n",
    "    difficulty_metrics = session_to_difficulty_metrics[session]\n",
    "    print(difficulty_metrics)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: -0.03, 0.19, 0.07, 0.55, -0.60, 2.48, -1.80, -0.00, 2.16, 0.26, 0.21, 0.05, 0.03\n",
      "R2 (discretized): 0.537\n",
      "R2 (continuous):  0.596\n",
      "QWK: 0.711\n",
      "  |  0  1  2  3  4  5  6 |\n",
      "--+----------------------+\n",
      "0 | <2>11  2  .  .  .  . |\n",
      "1 |  1 <3> 2  .  .  .  . |\n",
      "2 |  1  2<11> 4  .  .  . |\n",
      "3 |  .  1 18<35> .  .  . |\n",
      "4 |  .  .  .  . <.> .  . |\n",
      "5 |  .  .  .  .  . <.> . |\n",
      "6 |  .  .  .  .  .  . <.>|\n",
      "--+----------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Raw accuracy: 0.548\n"
     ]
    }
   ],
   "source": [
    "run_regressor(grade_2_matrix, feature_cols=feature_cols, col_to_predict='gyorJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: -0.03, 0.06, 0.03, 0.37, -0.33, 2.02, -0.58, -0.00, 0.66, 0.19, 0.15, 0.04, 0.04\n",
      "R2 (discretized): 0.679\n",
      "R2 (continuous):  0.709\n",
      "QWK: 0.828\n",
      "  |  0  1  2  3  4  5  6 |\n",
      "--+----------------------+\n",
      "0 | <4> 2  .  .  .  .  . |\n",
      "1 |  .<13> 4  .  .  .  . |\n",
      "2 |  .  5<11> 2  .  .  . |\n",
      "3 |  .  . 15<37> .  .  . |\n",
      "4 |  .  .  .  . <.> .  . |\n",
      "5 |  .  .  .  .  . <.> . |\n",
      "6 |  .  .  .  .  .  . <.>|\n",
      "--+----------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Raw accuracy: 0.699\n"
     ]
    }
   ],
   "source": [
    "run_regressor(grade_2_matrix, feature_cols=feature_cols, col_to_predict='gyorL')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
