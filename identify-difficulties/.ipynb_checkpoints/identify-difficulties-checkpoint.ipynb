{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying difficulties in a single reading session using text-analysis and performance matrices\n",
    "\n",
    "Inputs:\n",
    "- Text-analysis matrix for a passage\n",
    "- Performance matrix for session (three readings)\n",
    "\n",
    "Output:\n",
    "- Report of text-analysis fields where problems are detected\n",
    "\n",
    "*Methodological hurdles*: \n",
    "\n",
    "1. Linguistic: How do we distinguish words on which a reader struggles?\n",
    "2. Computational: How do we decide if a reader is struggling on a particular text-analysis field enough for us to consider it a 'problem-area?'\n",
    "\n",
    "## Solution to linguistic hurdle (very naive)\n",
    "Define\n",
    "- $d$: threshold duration for a `<pause>` marker to count as a pause, say 25 (frames).\n",
    "\n",
    "If a reader misses a word or pauses for $d$ frames before a word, we label that word as \"difficult.\"\n",
    "\n",
    "**Future consideration**: Readers may pause at the beginning of a small phrase (**NP**s or **PP**s) if the phrase contains a difficult word. (For instance, pausing before reading the phrase \"*of the organization*\".) To account for this, we can devise a way to incorporate constituency parses into the above methodology.\n",
    "\n",
    "## Solution to computational hurdle (less naive)\n",
    "*Assume we can accurately identify words that a reader struggles on, and we wish to determine if the reader is struggling on words for a quality $Q$.*\n",
    "\n",
    "Define \n",
    "- $D_i$: the set of words that a reader has trouble on reading $i$\n",
    "- $Q_i$ the set of words in reading $i$ with quality $Q$.\n",
    "- $n_{\\text{readings}}$: the threshold number of readings in which a reader needs to show difficulty, say 1 or 2\n",
    "- $p$: the threshold overlap proportion for words in a particular reading on which a reader needs to show difficulty, say 0.5.\n",
    "\n",
    "If $Q$ is a binary-valued (e.g. $Q=$ words that are decodable at the reader's grade level), we can reduce this task to:\n",
    "\n",
    "If for at least $n_{\\text{readings}}$ of readings $i$ we observe that\n",
    "$$\n",
    "\\frac{|D_i\\cap Q_i|}{Q_i}>p\\quad\\text{or}\\quad\\frac{|D_i\\cap Q_i^c|}{Q_i^c}>p,\n",
    "$$\n",
    "then we report that the reader is struggling on quality $Q$.\n",
    "\n",
    "If $Q$ is discrete but not binary-valued (e.g. number of letters), we modify this approach. Suppose $Q$ takes on values $\\{q_1,\\dots,q_k\\}$. Then we report each $q_m$ for which\n",
    "$$\n",
    "\\frac{|D_i\\cap Q^{(m)}_i|}{Q^{(m)}_i}>p\\quad\\text{or}\\quad\\frac{|D_i\\cap Q_i^{(m)c}|}{Q_i^{(m)c}}>p,\n",
    "$$\n",
    "where $Q^{(m)}_i$ is the set of words in reading $i$ whose value for quality $Q$ falls in the range $<q_m$.\n",
    "\n",
    "If $Q$ is continuous and ranges from $[a,b]$, we repeat the above process with a fixed partition of $[a,b]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD_PAUSE_DURATION = 25\n",
    "THRESHOLD_NUMBER_OF_DIFFICULT_READINGS = 1\n",
    "THRESHOLD_OVERLAP_PROPORTION = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
