{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Better\" boundary-based feature for constituency parses\n",
    "\n",
    "Following suggestions brought up in meeting on 7/9/20.\n",
    "\n",
    "Andrew Yang 7/11/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ycm/opt/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import sys, os, json, string\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from benepar.spacy_plugin import BeneparComponent\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(BeneparComponent('benepar_en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load an example sentence and generate a constituency parse for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_to_passage = {}\n",
    "with open('data/moby-passages-36/passages-with-line-breaks.tsv') as f:\n",
    "    for line in f:\n",
    "        item, passage = line.strip().split('\\t')\n",
    "        item_to_passage[item] = passage[:passage.index('#')]\n",
    "item_to_passage_cleaned = {item: passage.replace('$$', ' ').replace('$', '') for item, passage in item_to_passage.items()}\n",
    "doc_330 = nlp(item_to_passage_cleaned['330'])\n",
    "sent = list(doc_330.sents)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following constituency parse is hard to interpret:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[S [NP [NNP Sam] [CC and] [NNP Jo]] [VP [VBD smiled] [, ,] [S [VP [VBG knowing] [SBAR [S [NP [DT the] [NNS squirrels]] [VP [VBD were] [ADJP [JJ safe] [PP [IN with] [NP [PRP$ their] [NN mother]]]]]]]]]] [. .]]\n"
     ]
    }
   ],
   "source": [
    "print(sent._.parse_string.replace('(', '[').replace(')', ']'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"misc/fig-parse-tree-last-sentence.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the constituencies identified in the parse tree are arcane. Why does it matter that *the squirrels were safe with their mother* is an **S** contained inside an **SBAR**?\n",
    "\n",
    "Below is a more interpretable way of analyzing constituencies. It identifies constituencies that are more \"reasonable-sounding\" than simply reading off the constituency parse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_parent_lists(sent):\n",
    "    # ._.children field is hard to use\n",
    "    token_to_parents = {}\n",
    "    for token in sent:\n",
    "        parents = []\n",
    "        curr = token\n",
    "        while curr._.parent is not None:\n",
    "            curr = curr._.parent\n",
    "            parents.append(curr)\n",
    "        token_to_parents[token] = parents\n",
    "    deepest = max(len(parents) for token, parents in token_to_parents.items())\n",
    "    adjusted = {\n",
    "        token: [None] * (deepest - len(parents)) + parents\n",
    "        for token, parents in token_to_parents.items()\n",
    "    }\n",
    "    level_to_constituents = defaultdict(set)\n",
    "    for i in range(deepest):\n",
    "        for token, parents in adjusted.items():\n",
    "            i_constituent = parents[-i - 1]\n",
    "            if i_constituent:\n",
    "                level_to_constituents[i].add(i_constituent)\n",
    "    return level_to_constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 0 {Sam and Jo went for a hike.}\n",
      "depth 1 {went for a hike, Sam and Jo}\n",
      "depth 2 {for a hike}\n",
      "depth 3 {a hike}\n",
      "\n",
      "depth 0 {They took a path through the woods.}\n",
      "depth 1 {took a path through the woods}\n",
      "depth 2 {a path through the woods}\n",
      "depth 3 {a path, through the woods}\n",
      "depth 4 {the woods}\n",
      "\n",
      "depth 0 {Suddenly, Sam heard a noise coming from the tree above their heads.}\n",
      "depth 1 {heard a noise coming from the tree above their heads}\n",
      "depth 2 {a noise coming from the tree above their heads}\n",
      "depth 3 {coming from the tree above their heads, a noise}\n",
      "depth 4 {from the tree above their heads}\n",
      "depth 5 {the tree above their heads}\n",
      "depth 6 {the tree, above their heads}\n",
      "depth 7 {their heads}\n",
      "\n",
      "depth 0 {Jo climbed up to see what the noise was and found two baby squirrels.}\n",
      "depth 1 {climbed up to see what the noise was and found two baby squirrels}\n",
      "depth 2 {climbed up to see what the noise was, found two baby squirrels}\n",
      "depth 3 {two baby squirrels, to see what the noise was}\n",
      "depth 4 {see what the noise was}\n",
      "depth 5 {what the noise was}\n",
      "depth 6 {the noise was}\n",
      "depth 7 {the noise}\n",
      "\n",
      "depth 0 {The babies were alone, but their mother must be somewhere near.}\n",
      "depth 1 {their mother must be somewhere near, The babies were alone}\n",
      "depth 2 {The babies, were alone, their mother, must be somewhere near}\n",
      "depth 3 {be somewhere near}\n",
      "depth 4 {somewhere near}\n",
      "\n",
      "depth 0 {The children watched and waited.}\n",
      "depth 1 {The children, watched and waited}\n",
      "\n",
      "depth 0 {Sure enough, the mother soon returned with a mouthful of nuts.}\n",
      "depth 1 {the mother, Sure enough, returned with a mouthful of nuts}\n",
      "depth 2 {with a mouthful of nuts}\n",
      "depth 3 {a mouthful of nuts}\n",
      "depth 4 {a mouthful, of nuts}\n",
      "\n",
      "depth 0 {The noises stopped as the baby squirrels began to eat.}\n",
      "depth 1 {The noises, stopped as the baby squirrels began to eat}\n",
      "depth 2 {as the baby squirrels began to eat}\n",
      "depth 3 {the baby squirrels began to eat}\n",
      "depth 4 {began to eat, the baby squirrels}\n",
      "depth 5 {to eat}\n",
      "\n",
      "depth 0 {Sam and Jo smiled, knowing the squirrels were safe with their mother.}\n",
      "depth 1 {Sam and Jo, smiled, knowing the squirrels were safe with their mother}\n",
      "depth 2 {knowing the squirrels were safe with their mother}\n",
      "depth 3 {the squirrels were safe with their mother}\n",
      "depth 4 {were safe with their mother, the squirrels}\n",
      "depth 5 {safe with their mother}\n",
      "depth 6 {with their mother}\n",
      "depth 7 {their mother}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in list(doc_330.sents):\n",
    "    for k, v in compile_parent_lists(s).items():\n",
    "        print('depth', k, v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these new constituencies, I propose the following family of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_contained_in_constituent(token, const):\n",
    "    curr = token\n",
    "    while curr._.parent is not None:\n",
    "        curr = curr._.parent\n",
    "        if type(curr) == type(const):\n",
    "            if curr == const:\n",
    "                return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_k_sisters(sent, k=1):\n",
    "    '''\n",
    "    for each token:\n",
    "        1 if the token and its preceding token belong to the same constituency k level beneath the root\n",
    "    '''\n",
    "    rv = [0]\n",
    "    levels_to_constituents = compile_parent_lists(sent)\n",
    "    for idx, token in enumerate(sent):\n",
    "        if idx == 0:\n",
    "            continue\n",
    "        prev_token = sent[idx - 1]\n",
    "        match = 0\n",
    "        for c in levels_to_constituents[k]:\n",
    "            if is_contained_in_constituent(token, c) and is_contained_in_constituent(prev_token, c):\n",
    "                match = 1\n",
    "                break\n",
    "        rv.append(match)\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_sisters(sent, k):\n",
    "    x = depth_k_sisters(sent, k)\n",
    "    print(x)\n",
    "    for idx, val in enumerate(x):\n",
    "        if val == 0:\n",
    "            print('\\n' + str(sent[idx]), end=' ')\n",
    "        else:\n",
    "            print(sent[idx], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "Sam and Jo smiled , knowing the squirrels were safe with their mother . "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters(sent, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "\n",
      "Sam and Jo \n",
      "smiled , knowing the squirrels were safe with their mother \n",
      ". "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters(sent, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "\n",
      "Sam \n",
      "and \n",
      "Jo \n",
      "smiled \n",
      ", \n",
      "knowing the squirrels were safe with their mother \n",
      ". "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters(sent, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0]\n",
      "\n",
      "Sam \n",
      "and \n",
      "Jo \n",
      "smiled \n",
      ", \n",
      "knowing \n",
      "the squirrels were safe with their mother \n",
      ". "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters(sent, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0]\n",
      "\n",
      "Sam \n",
      "and \n",
      "Jo \n",
      "smiled \n",
      ", \n",
      "knowing \n",
      "the squirrels \n",
      "were safe with their mother \n",
      ". "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters(sent, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "\n",
      "Sam \n",
      "and \n",
      "Jo \n",
      "smiled \n",
      ", \n",
      "knowing \n",
      "the \n",
      "squirrels \n",
      "were \n",
      "safe with their mother \n",
      ". "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters(sent, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
      "\n",
      "Sam \n",
      "and \n",
      "Jo \n",
      "smiled \n",
      ", \n",
      "knowing \n",
      "the \n",
      "squirrels \n",
      "were \n",
      "safe \n",
      "with their mother \n",
      ". "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters(sent, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "\n",
      "Sam \n",
      "and \n",
      "Jo \n",
      "smiled \n",
      ", \n",
      "knowing \n",
      "the \n",
      "squirrels \n",
      "were \n",
      "safe \n",
      "with \n",
      "their mother \n",
      ". "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters(sent, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table(doc):\n",
    "    doc_deepest = max(len(compile_parent_lists(sent).keys()) for idx, sent in enumerate(list(doc.sents)))\n",
    "    rows = []\n",
    "    for i in range(doc_deepest):\n",
    "        row = []\n",
    "        for idx, sent in enumerate(list(doc.sents)):\n",
    "            row += depth_k_sisters(sent, i)\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(np.array(rows).transpose())\n",
    "    df.columns = ['depth_sister_' + str(i) for i in range(doc_deepest)]\n",
    "    tokens = [str(t) for sent in doc.sents for t in sent]\n",
    "    df.index = tokens\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_table(doc_330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth_sister_0</th>\n",
       "      <th>depth_sister_1</th>\n",
       "      <th>depth_sister_2</th>\n",
       "      <th>depth_sister_3</th>\n",
       "      <th>depth_sister_4</th>\n",
       "      <th>depth_sister_5</th>\n",
       "      <th>depth_sister_6</th>\n",
       "      <th>depth_sister_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sam</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jo</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      depth_sister_0  depth_sister_1  depth_sister_2  depth_sister_3  \\\n",
       "Sam                0               0               0               0   \n",
       "and                1               1               0               0   \n",
       "Jo                 1               1               0               0   \n",
       "went               1               0               0               0   \n",
       "for                1               1               0               0   \n",
       "\n",
       "      depth_sister_4  depth_sister_5  depth_sister_6  depth_sister_7  \n",
       "Sam                0               0               0               0  \n",
       "and                0               0               0               0  \n",
       "Jo                 0               0               0               0  \n",
       "went               0               0               0               0  \n",
       "for                0               0               0               0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('output/20200711_text_matrix_330_addendum_depth_k_sisters.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottom_up_representation(sent):\n",
    "    constituent_to_depth = {}\n",
    "    token_to_parents = {}\n",
    "    for token in sent:\n",
    "        curr = token\n",
    "        depth = 1\n",
    "        parents = set()\n",
    "        while curr._.parent:\n",
    "            curr = curr._.parent\n",
    "            parents.add(curr)\n",
    "            if curr not in constituent_to_depth:\n",
    "                constituent_to_depth[curr] = depth\n",
    "            constituent_to_depth[curr] = max(depth, constituent_to_depth[curr])\n",
    "            depth += 1\n",
    "        token_to_parents[token] = parents\n",
    "    return constituent_to_depth, token_to_parents\n",
    "\n",
    "def bottom_up_feature_vector(sent, k=1):\n",
    "    rv = [0]\n",
    "    constituent_to_depth, token_to_parents = bottom_up_representation(sent)\n",
    "    for idx, token in enumerate(sent):\n",
    "        if idx == 0:\n",
    "            continue\n",
    "        prev_token = sent[idx - 1]\n",
    "        \n",
    "        common_ancestors = token_to_parents[token] & token_to_parents[prev_token]\n",
    "        common_ancestors_depths = set(constituent_to_depth[anc] for anc in common_ancestors)\n",
    "        \n",
    "        if k in common_ancestors_depths:\n",
    "            rv.append(1)\n",
    "        else:\n",
    "            rv.append(0)\n",
    "    return rv\n",
    "\n",
    "def pretty_print_sisters_bottom_up(sent, k):\n",
    "    x = bottom_up_feature_vector(sent, k)\n",
    "    print(x)\n",
    "    for idx, val in enumerate(x):\n",
    "        if val == 0:\n",
    "            print('\\n' + str(sent[idx]), end=' ')\n",
    "        else:\n",
    "            print(sent[idx], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "\n",
      "Sam and Jo \n",
      "smiled \n",
      ", \n",
      "knowing \n",
      "the squirrels \n",
      "were \n",
      "safe \n",
      "with \n",
      "their mother \n",
      ". "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters_bottom_up(sent, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
      "\n",
      "Sam \n",
      "and \n",
      "Jo \n",
      "smiled \n",
      ", \n",
      "knowing \n",
      "the \n",
      "squirrels \n",
      "were \n",
      "safe \n",
      "with their mother \n",
      ". "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters_bottom_up(sent, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "\n",
      "Sam \n",
      "and \n",
      "Jo \n",
      "smiled \n",
      ", \n",
      "knowing \n",
      "the \n",
      "squirrels \n",
      "were \n",
      "safe with their mother \n",
      ". "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters_bottom_up(sent, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0]\n",
      "\n",
      "Sam \n",
      "and \n",
      "Jo \n",
      "smiled \n",
      ", \n",
      "knowing \n",
      "the \n",
      "squirrels \n",
      "were safe with their mother \n",
      ". "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters_bottom_up(sent, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0]\n",
      "\n",
      "Sam \n",
      "and \n",
      "Jo \n",
      "smiled \n",
      ", \n",
      "knowing \n",
      "the squirrels were safe with their mother \n",
      ". "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters_bottom_up(sent, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "\n",
      "Sam \n",
      "and \n",
      "Jo \n",
      "smiled \n",
      ", \n",
      "knowing the squirrels were safe with their mother \n",
      ". "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters_bottom_up(sent, k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "\n",
      "Sam \n",
      "and \n",
      "Jo \n",
      "smiled , knowing the squirrels were safe with their mother \n",
      ". "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters_bottom_up(sent, k=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "Sam and Jo smiled , knowing the squirrels were safe with their mother . "
     ]
    }
   ],
   "source": [
    "pretty_print_sisters_bottom_up(sent, k=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table_bottom_up(doc):\n",
    "    deepest = -1\n",
    "    for sent in doc.sents: \n",
    "        constituent_to_depth, _ = bottom_up_representation(sent)\n",
    "        deepest = max(deepest, max(d for _, d in constituent_to_depth.items()))\n",
    "    rows = []\n",
    "    titles = []\n",
    "    for k in range(1, deepest + 1):\n",
    "        titles.append('bottom_up_' + str(k))\n",
    "        rows.append([val for s in doc.sents for val in bottom_up_feature_vector(s, k)])\n",
    "    df = pd.DataFrame(np.array(rows).T)\n",
    "    df.columns = titles\n",
    "    tokens = [str(t) for sent in doc.sents for t in sent]\n",
    "    df.index = tokens\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_table_bottom_up(doc_330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bottom_up_1</th>\n",
       "      <th>bottom_up_2</th>\n",
       "      <th>bottom_up_3</th>\n",
       "      <th>bottom_up_4</th>\n",
       "      <th>bottom_up_5</th>\n",
       "      <th>bottom_up_6</th>\n",
       "      <th>bottom_up_7</th>\n",
       "      <th>bottom_up_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sam</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jo</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bottom_up_1  bottom_up_2  bottom_up_3  bottom_up_4  bottom_up_5  \\\n",
       "Sam             0            0            0            0            0   \n",
       "and             1            0            0            1            0   \n",
       "Jo              1            0            0            1            0   \n",
       "went            0            0            0            1            0   \n",
       "for             0            0            1            1            0   \n",
       "\n",
       "      bottom_up_6  bottom_up_7  bottom_up_8  \n",
       "Sam             0            0            0  \n",
       "and             0            0            0  \n",
       "Jo              0            0            0  \n",
       "went            0            0            0  \n",
       "for             0            0            0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_position_in_constituency(sent):\n",
    "    constituent_to_depth, token_to_parents = bottom_up_representation(sent)\n",
    "    initial_vec, middle_vec, final_vec = [], [], []\n",
    "    amt = 1 / len(constituent_to_depth.keys())\n",
    "    for token in sent:\n",
    "        parents = token_to_parents[token]\n",
    "        initial = 0\n",
    "        middle = 0\n",
    "        final = 0\n",
    "        for parent in parents:\n",
    "            parent_tokens = [t for t in parent]\n",
    "            if token == parent_tokens[0]:\n",
    "                initial += amt\n",
    "            if token == parent_tokens[-1]:\n",
    "                final += amt\n",
    "            if token != parent_tokens[0] and token != parent_tokens[-1]:\n",
    "                middle += amt\n",
    "        initial_vec.append(initial)\n",
    "        middle_vec.append(middle)\n",
    "        final_vec.append(final)\n",
    "    return initial_vec, middle_vec, final_vec\n",
    "\n",
    "def generate_table_constituency_counts(doc):\n",
    "    full_i_v, full_m_v, full_f_v = [], [], []\n",
    "    for sent in doc.sents:\n",
    "        i_v, m_v, f_v = token_position_in_constituency(sent)\n",
    "        full_i_v += i_v\n",
    "        full_m_v += m_v\n",
    "        full_f_v += f_v\n",
    "    arr = [full_i_v, full_m_v, full_f_v]\n",
    "    arr = np.array(arr).T\n",
    "    df = pd.DataFrame(arr, columns=['n_constituents_initial', 'n_constituents_middle', 'n_constituents_final'])\n",
    "    tokens = [str(t) for sent in doc.sents for t in sent]\n",
    "    df.index = tokens\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output/20200714_text_matrix_330_addendum_bottom_up.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = generate_table_constituency_counts(doc_330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_constituents_initial</th>\n",
       "      <th>n_constituents_middle</th>\n",
       "      <th>n_constituents_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sam</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_constituents_initial  n_constituents_middle  n_constituents_final\n",
       "Sam                      0.4                    0.0                   0.0\n",
       "and                      0.0                    0.4                   0.0\n",
       "Jo                       0.0                    0.2                   0.2\n",
       "went                     0.2                    0.2                   0.0\n",
       "for                      0.2                    0.4                   0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output/20200714_text_matrix_330_addendum_positions.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
