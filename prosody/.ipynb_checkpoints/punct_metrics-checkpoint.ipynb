{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json, termcolor\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "from collections import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/moby/jsons/item_to_passage_new.json') as f:\n",
    "    item_to_passage = json.load(f)\n",
    "with open('../data/moby/jsons/item_to_recstring_new.json') as f:\n",
    "    item_to_recstring = json.load(f)\n",
    "with open('../data/moby/jsons/item_to_form.json') as f:\n",
    "    item_to_form = json.load(f)\n",
    "with open('item_to_expected_pauses_mask.json') as f:\n",
    "    item_to_expected_pauses_mask = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_punct = {'.', ',', '?', '!'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_to_punctuation_indices = defaultdict(list)\n",
    "for item, passage in item_to_passage.items():\n",
    "    recstring = item_to_recstring[item].split()\n",
    "    passage_no_quotes = passage.replace('\"', '')\n",
    "    passage_no_quotes_tokenized = passage_no_quotes.split()\n",
    "    for idx, token in enumerate(passage_no_quotes_tokenized):\n",
    "        if token[-1] in target_punct and token != 'Ms.':\n",
    "#             termcolor.cprint(token, 'red', end=' ')\n",
    "#             print(recstring[idx])\n",
    "            item_to_punctuation_indices[item].append((idx, token, recstring[idx]))\n",
    "        else:\n",
    "#             print(token, end=' ')\n",
    "            pass\n",
    "#     print()\n",
    "item_to_punctuation_indices = dict(item_to_punctuation_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_thresholds_red = {\n",
    "    'Grade1Fall': 0.5,\n",
    "    'Grade1Winter': 0.4,\n",
    "    'Grade1Spring': 0.4,\n",
    "    'Grade2Fall': 0.4,\n",
    "    'Grade2Winter': 0.4,\n",
    "    'Grade2Spring': 0.4,\n",
    "    'Grade3Fall': 0.4,\n",
    "    'Grade3Winter': 0.4,\n",
    "    'Grade3Spring': 0.3,\n",
    "    'Grade4Fall': 0.3,\n",
    "    'Grade4Winter': 0.3,\n",
    "    'Grade4Spring': 0.3 \n",
    "}\n",
    "eval_thresholds_yellow = {\n",
    "    'Grade1Fall': 0.3,\n",
    "    'Grade1Winter': 0.3,\n",
    "    'Grade1Spring': 0.3,\n",
    "    'Grade2Fall': 0.2,\n",
    "    'Grade2Winter': 0.2,\n",
    "    'Grade2Spring': 0.2,\n",
    "    'Grade3Fall': 0.2,\n",
    "    'Grade3Winter': 0.2,\n",
    "    'Grade3Spring': 0.2,\n",
    "    'Grade4Fall': 0.2,\n",
    "    'Grade4Winter': 0.2,\n",
    "    'Grade4Spring': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Item\\tPrePunctTokenIndices')\n",
    "list_item = []\n",
    "list_form = []\n",
    "list_prepunct_indices = []\n",
    "list_prepunct_tokens = []\n",
    "list_signif_indices = []\n",
    "list_signif_tokens = []\n",
    "list_red_threshold = []\n",
    "list_yellow_threshold = []\n",
    "list_pause_signif_threshold = []\n",
    "list_child_norm_signif_threshold = []\n",
    "list_passage_correctness_threshold = []\n",
    "\n",
    "for item, idxs in item_to_punctuation_indices.items():\n",
    "    list_item.append(item)\n",
    "    idxs_no_final = idxs[:-1]\n",
    "    form = item_to_form[item]\n",
    "    list_form.append(form)\n",
    "    \n",
    "    signif = [x for i, x in enumerate(idxs_no_final) if item_to_expected_pauses_mask[item][i]]\n",
    "    assert len(item_to_expected_pauses_mask[item]) == len(idxs) - 1, item\n",
    "    \n",
    "    list_prepunct_indices.append(','.join([str(x[0]) for x in idxs_no_final]))\n",
    "    list_prepunct_tokens.append(','.join([x[-1] for x in idxs_no_final]))\n",
    "    \n",
    "    list_signif_indices.append(','.join([str(x[0]) for x in signif]))\n",
    "    list_signif_tokens.append(','.join([x[-1] for x in signif]))\n",
    "    \n",
    "    list_red_threshold.append(eval_thresholds_red[form])\n",
    "    list_yellow_threshold.append(eval_thresholds_yellow[form])\n",
    "    \n",
    "    list_pause_signif_threshold.append(30)\n",
    "    list_child_norm_signif_threshold.append(10)\n",
    "    list_passage_correctness_threshold.append(0.5)\n",
    "    \n",
    "#     print(item + '\\t' + ','.join([str(x[0]) for x in idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({\n",
    "#     'Item': list_item,\n",
    "#     'Form': list_form,\n",
    "#     'PrePunctTokens': list_prepunct_tokens,\n",
    "#     'PrePunctTokenIndices': list_prepunct_indices,\n",
    "#     'SignifTokens': list_signif_tokens,\n",
    "#     'SignifTokenIndices': list_signif_indices,\n",
    "#     'RedThreshold': list_red_threshold,\n",
    "#     'YellowThreshold': list_yellow_threshold,\n",
    "#     'PauseSignificanceThreshold': list_pause_signif_threshold,\n",
    "#     'ChildNormalizedPauseSignificanceThreshold': list_child_norm_signif_threshold,\n",
    "#     'PassageCorrectnessThreshold': list_passage_correctness_threshold\n",
    "# }).to_csv('prepunct_table_with_signif.tsv', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_for_response(table, idx):\n",
    "    pause_length_after_token = table.iloc[idx + 1].nframes\n",
    "    \n",
    "    f0_minus_2 = table.iloc[idx - 4].pitch_mean\n",
    "    f0_minus_1 = table.iloc[idx - 2].pitch_mean\n",
    "    f0_plus_1  = table.iloc[idx + 2].pitch_mean\n",
    "    f0_plus_2  = table.iloc[idx + 4].pitch_mean\n",
    "    \n",
    "    ratio_before = f0_minus_2 / f0_minus_1\n",
    "    ratio_after  = f0_plus_1 / f0_plus_2\n",
    "    \n",
    "    if ratio_before != ratio_before:\n",
    "        ratio_before = 0\n",
    "    if ratio_after != ratio_after:\n",
    "        aratio_after = 0\n",
    "    \n",
    "    ratio_before_max = max(f0_minus_2, f0_minus_1)\n",
    "    ratio_after_max  = max(f0_plus_1, f0_plus_2)\n",
    "    \n",
    "    return {\n",
    "        'pause_length_after_token': pause_length_after_token,\n",
    "        'ratio_before': ratio_before,\n",
    "        'ratio_after': ratio_after,\n",
    "        'ratio_before_max': ratio_before_max,\n",
    "        'ratio_after_max': ratio_after_max\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ycm/opt/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/ycm/opt/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/Users/ycm/opt/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "perfmat_dir = '../output/performance-matrix/all-fixed/'\n",
    "\n",
    "item_to_punct_location_to_stats = defaultdict(list)\n",
    "\n",
    "for item_dir in os.listdir(perfmat_dir):\n",
    "    if item_dir.endswith('-182'):\n",
    "        item = item_dir.replace('-182', '')\n",
    "        punct_indices = item_to_punctuation_indices[item]\n",
    "        punct_indices_perfmat = [xyz[0] * 2 + 1 for xyz in punct_indices]\n",
    "        \n",
    "        punct_location_to_stats = defaultdict(list)\n",
    "        \n",
    "        for perfmat_file in os.listdir(os.path.join(perfmat_dir, item_dir)):\n",
    "            if not perfmat_file.endswith('tsv'):\n",
    "                continue\n",
    "            perf_mat = pd.read_csv(os.path.join(perfmat_dir, item_dir, perfmat_file), sep='\\t')\n",
    "            \n",
    "            for _idx, idx in enumerate(punct_indices_perfmat[:-1]):\n",
    "                metrics = get_metrics_for_response(perf_mat, idx)\n",
    "                \n",
    "                punct_location_to_stats[(idx,\n",
    "                                         punct_indices[_idx][1],\n",
    "                                         punct_indices[_idx][2])].append(metrics)\n",
    "                \n",
    "                assert perf_mat.iloc[idx]['Unnamed: 0'] == punct_indices[_idx][2]\n",
    "        \n",
    "        as_list_punct_location_to_stats = sorted(list([*x, y] for x, y in punct_location_to_stats.items()), key=lambda x: x[0])\n",
    "        item_to_punct_location_to_stats[item] = as_list_punct_location_to_stats\n",
    "#             break\n",
    "#         break\n",
    "\n",
    "item_to_punct_location_to_stats = dict(item_to_punct_location_to_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stats_table(item):\n",
    "    pause_min_c  = []\n",
    "    pause_max_c  = []\n",
    "    pause_1q_c   = []\n",
    "    pause_3q_c   = []\n",
    "    pause_med_c  = []\n",
    "    pause_mean_c = []\n",
    "    pause_sstd_c = []\n",
    "    \n",
    "    f0ratio_before_min_c  = []\n",
    "    f0ratio_before_max_c  = []\n",
    "    f0ratio_before_1q_c   = []\n",
    "    f0ratio_before_3q_c   = []\n",
    "    f0ratio_before_med_c  = []\n",
    "    f0ratio_before_mean_c = []\n",
    "    f0ratio_before_sstd_c = [] \n",
    "    \n",
    "    f0_before_max_med_c = []\n",
    "    f0_after_max_med_c  = []\n",
    "\n",
    "    f0ratio_after_min_c  = []\n",
    "    f0ratio_after_max_c  = []\n",
    "    f0ratio_after_1q_c   = []\n",
    "    f0ratio_after_3q_c   = []\n",
    "    f0ratio_after_med_c  = []\n",
    "    f0ratio_after_mean_c = []\n",
    "    f0ratio_after_sstd_c = [] \n",
    "    \n",
    "    punct_data = item_to_punct_location_to_stats[item]\n",
    "    \n",
    "    for idx, token, token_with_punct, stats in punct_data:\n",
    "        pause_lengths = [d['pause_length_after_token'] for d in stats]\n",
    "        f0ratio_before = np.array([d['ratio_before'] for d in stats])\n",
    "        f0ratio_after = np.array([d['ratio_after'] for d in stats])\n",
    "        f0_before_max = np.array([d['ratio_before_max'] for d in stats])\n",
    "        f0_after_max  = np.array([d['ratio_after_max'] for d in stats])\n",
    "        \n",
    "        f0ratio_before = [x for x in f0ratio_before if (not np.isnan(x)) and np.isfinite(x)]\n",
    "        f0ratio_after = [x for x in f0ratio_after if (not np.isnan(x)) and np.isfinite(x)]\n",
    "        \n",
    "        pause_min_c.append(np.min(pause_lengths))\n",
    "        pause_max_c.append(np.max(pause_lengths))\n",
    "        pause_1q_c.append(np.percentile(pause_lengths, 25))\n",
    "        pause_3q_c.append(np.percentile(pause_lengths, 75))\n",
    "        pause_med_c.append(np.median(pause_lengths))\n",
    "        pause_mean_c.append(np.mean(pause_lengths))\n",
    "        pause_sstd_c.append(np.std(pause_lengths, ddof=1))\n",
    "        \n",
    "        f0_before_max_med_c.append(np.median(f0_before_max))\n",
    "        f0_after_max_med_c.append(np.median(f0_after_max))\n",
    "        \n",
    "        f0ratio_before_min_c.append(np.min(f0ratio_before))\n",
    "        f0ratio_before_max_c.append(np.max(f0ratio_before))\n",
    "        f0ratio_before_1q_c.append(np.percentile(f0ratio_before, 25))\n",
    "        f0ratio_before_3q_c.append(np.percentile(f0ratio_before, 75))\n",
    "        f0ratio_before_med_c.append(np.median(f0ratio_before))\n",
    "        f0ratio_before_mean_c.append(np.mean(f0ratio_before))\n",
    "        f0ratio_before_sstd_c.append(np.std(f0ratio_before, ddof=1))\n",
    "        \n",
    "        f0ratio_after_min_c.append(np.min(f0ratio_after))\n",
    "        f0ratio_after_max_c.append(np.max(f0ratio_after))\n",
    "        f0ratio_after_1q_c.append(np.percentile(f0ratio_after, 25))\n",
    "        f0ratio_after_3q_c.append(np.percentile(f0ratio_after, 75))\n",
    "        f0ratio_after_med_c.append(np.median(f0ratio_after))\n",
    "        f0ratio_after_mean_c.append(np.mean(f0ratio_after))\n",
    "        f0ratio_after_sstd_c.append(np.std(f0ratio_after, ddof=1))\n",
    "    \n",
    "    stats_table = {\n",
    "        'form': item_to_form[item],\n",
    "        'item': item,\n",
    "        'perfmat_idx': [x[0] for x in punct_data],\n",
    "        'token': [x[2] for x in punct_data],\n",
    "        'punct': [x[1][-1] for x in punct_data],\n",
    "        'pause_min': pause_min_c,\n",
    "        'pause_max': pause_max_c,\n",
    "        'pause_1q': pause_1q_c,\n",
    "        'pause_3q': pause_3q_c, \n",
    "        'pause_med': pause_med_c,\n",
    "        'pause_mean': pause_mean_c,\n",
    "        'pause_sstd': pause_sstd_c,\n",
    "        'f0_before_max_med': f0_before_max_med_c,\n",
    "        'f0_after_max_med': f0_after_max_med_c,\n",
    "        'f0ratio_before_min': f0ratio_before_min_c,\n",
    "        'f0ratio_before_max': f0ratio_before_max_c,\n",
    "        'f0ratio_before_1q': f0ratio_before_1q_c,\n",
    "        'f0ratio_before_3q': f0ratio_before_3q_c, \n",
    "        'f0ratio_before_med': f0ratio_before_med_c,\n",
    "        'f0ratio_before_mean': f0ratio_before_mean_c,\n",
    "        'f0ratio_before_sstd': f0ratio_before_sstd_c,\n",
    "        'f0ratio_after_min': f0ratio_after_min_c,\n",
    "        'f0ratio_after_max': f0ratio_after_max_c,\n",
    "        'f0ratio_after_1q': f0ratio_after_1q_c,\n",
    "        'f0ratio_after_3q': f0ratio_after_3q_c, \n",
    "        'f0ratio_after_med': f0ratio_after_med_c,\n",
    "        'f0ratio_after_mean': f0ratio_after_mean_c,\n",
    "        'f0ratio_after_sstd': f0ratio_after_sstd_c\n",
    "    }\n",
    "    stats_df = pd.DataFrame(stats_table)\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dfs = [make_stats_table(item) for item in item_to_punct_location_to_stats]\n",
    "big_df = pd.concat(stats_dfs, ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.sort_values(['form', 'item']).reset_index().drop('index', axis=1).to_csv('gold_punct_metrics_updated.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
