{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json, string\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from benepar.spacy_plugin import BeneparComponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_to_passage = {}\n",
    "with open('data/moby-passages-36/passages-with-line-breaks.tsv') as f:\n",
    "    for line in f:\n",
    "        item, passage = line.strip().split('\\t')\n",
    "        item_to_passage[item] = passage[:passage.index('#')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_to_passage_cleaned = {item: passage.replace('$$', ' ').replace('$', '') for item, passage in item_to_passage.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(BeneparComponent('benepar_en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_330 = nlp(item_to_passage_cleaned['330'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_string_to_list(s):\n",
    "    punct = {'.', ',', '!', '?', \"'\", ';', ':', '$'}\n",
    "    rv = s[0]\n",
    "    for idx in range(1, len(s) - 1):\n",
    "        prev = s[idx - 1]\n",
    "        curr = s[idx]\n",
    "        nxt = s[idx + 1]\n",
    "        if prev == '(' and (curr.isalpha() or curr.isdigit() or curr in punct):\n",
    "            rv += \"'\"\n",
    "        if (prev.isalpha() or prev.isdigit() or prev in punct) and curr in ')':\n",
    "            rv += \"'\"\n",
    "        rv += curr\n",
    "        if (curr.isalpha() or curr.isdigit() or curr in punct) and nxt == ' ':\n",
    "            rv += \"'\"\n",
    "        if curr == ' ' and (nxt.isalpha() or nxt.isdigit() or nxt in punct):\n",
    "            rv += \"'\"\n",
    "    rv += s[-1]\n",
    "    return rv.replace('(', '[').replace(')', ']').replace(' ', ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_string = list(doc_330.sents)[0]._.parse_string\n",
    "lst = eval(parse_string_to_list(parse_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pos(root, pos_list):\n",
    "    tag = root[0]\n",
    "#     print(tag, end=' ')\n",
    "    if isinstance(root[1], str):\n",
    "        pos_list.append(tag)\n",
    "    else:\n",
    "        for child in root[1:]:\n",
    "            read_pos(child, pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NNP', 'CC', 'NNP', 'VBD', 'IN', 'DT', 'NN', '.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_list = []\n",
    "read_pos(lst, pos_list)\n",
    "pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parent_tags(child):\n",
    "    tags = []\n",
    "    curr = child\n",
    "    while True:\n",
    "        if curr._.parent:\n",
    "            tag = curr._.parent._.labels[-1]\n",
    "            if len(curr._.labels) <= 1:\n",
    "#             print(tag, curr._.labels, len(curr._.labels), curr, list(curr._.parent._.children))\n",
    "                tags.append(tag)\n",
    "            curr = curr._.parent\n",
    "        else:\n",
    "            break\n",
    "    return tags[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NP']\n",
      "['NP']\n",
      "['NP']\n",
      "['VP']\n",
      "['VP']\n",
      "['VP']\n",
      "['NP', 'S']\n",
      "['NP', 'S']\n",
      "['VP', 'S']\n",
      "['ADJP', 'VP', 'S']\n",
      "['PP', 'ADJP', 'VP', 'S']\n",
      "['NP', 'PP', 'ADJP', 'VP', 'S']\n",
      "['NP', 'PP', 'ADJP', 'VP', 'S']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# for sent in list(doc_330.sents):\n",
    "for token in list(doc_330.sents)[-1]:\n",
    "    print(read_parent_tags(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = []\n",
    "for idx, sentence in enumerate(list(doc_330.sents)):\n",
    "    rows = []\n",
    "    for token in sentence:\n",
    "#         if str(token) in string.punctuation:\n",
    "#             continue\n",
    "        parent_tags = set(read_parent_tags(token))\n",
    "        constituent_of_ADJP = 1 if 'ADJP' in parent_tags else 0\n",
    "        constituent_of_ADVP = 1 if 'ADVP' in parent_tags else 0\n",
    "        constituent_of_NP = 1 if 'NP' in parent_tags else 0\n",
    "        constituent_of_PP = 1 if 'PP' in parent_tags else 0\n",
    "        constituent_of_S_like = 1 if {'S', 'SBAR'} & parent_tags else 0\n",
    "        constituent_of_VP = 1 if 'VP' in parent_tags else 0\n",
    "        parent_depth = len(parent_tags)\n",
    "        \n",
    "        row = [\n",
    "            str(token),\n",
    "            constituent_of_ADJP,\n",
    "            constituent_of_ADVP,\n",
    "            constituent_of_NP,\n",
    "            constituent_of_PP,\n",
    "            constituent_of_S_like,\n",
    "            constituent_of_VP,\n",
    "            parent_depth\n",
    "        ]\n",
    "        \n",
    "        rows.append(row)\n",
    "        \n",
    "    parse_string = sentence._.parse_string\n",
    "    parse_list = eval(parse_string_to_list(parse_string))\n",
    "    pos_list = []\n",
    "    read_pos(parse_list, pos_list)\n",
    "    pos_gen = (x for x in pos_list)\n",
    "    rows = [row + [next(pos_gen)] for row in rows]\n",
    "    assert len(pos_list) == len(sentence)\n",
    "    for r in rows:\n",
    "        matrix.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\n",
    "    'token',\n",
    "    'constituent_of_ADJP',\n",
    "    'constituent_of_ADVP',\n",
    "    'constituent_of_NP',\n",
    "    'constituent_of_PP',\n",
    "    'constituent_of_S_like',\n",
    "    'constituent_of_VP',\n",
    "    'parent_depth',\n",
    "    'pos_tag'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df.pos_tag, prefix='pos')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/20200709_330_text_matrix_addendum.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
