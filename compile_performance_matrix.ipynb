{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling performance matrix\n",
    "\n",
    "This notebook should be self-contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, string, difflib\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For each item, load recstring and token-by-token representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_texts_and_recstrings = pd.read_csv('data/moby-passages-36/passages-with-line-break-and-recstring.tsv', sep='\\t')\n",
    "item_number_to_recstring = dict(zip(df_full_texts_and_recstrings.Item, df_full_texts_and_recstrings['Rec String']))\n",
    "df_text_with_line_breaks = pd.read_csv(\n",
    "    'data/moby-passages-36/passages-with-line-breaks.tsv',\n",
    "    sep='\\t',\n",
    "    names=['Item', 'Passage']\n",
    ")\n",
    "item_number_to_text_with_line_breaks = dict(zip(df_text_with_line_breaks.Item, df_text_with_line_breaks.Passage))\n",
    "item_number_to_text_with_line_breaks = {\n",
    "    k: v[:v.index('#')].replace('$$', ' PARBREAK ').replace('$', ' LINEBREAK ').replace(' 45 ', ' forty five ')\n",
    "    for k, v in item_number_to_text_with_line_breaks.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check that the token-by-token representation minus line/paragraph breaks matches the recstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Meg wanted to bake a pie. She asked her mother for help. PARBREAK They measured the flour, sugar, and butter for the crust.  LINEBREAK Her mother showed her how to roll out the crust. Meg sliced  LINEBREAK the apples and put them in the pie pan. They put the pie  LINEBREAK in the hot oven and waited forty five minutes. PARBREAK As the pie baked, a delicious smell filled the kitchen. When  LINEBREAK the timer rang, they took the pie out of the oven and  LINEBREAK set it on the window sill to cool.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_number_to_text_with_line_breaks[310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_token(token):\n",
    "    rv = token\n",
    "    while rv[0] in string.punctuation:\n",
    "        rv = rv[1:]\n",
    "    while rv[-1] in string.punctuation:\n",
    "        rv = rv[:-1]\n",
    "    return rv.lower()\n",
    "\n",
    "for item, text_with_breaks in item_number_to_text_with_line_breaks.items():\n",
    "    recstring = item_number_to_recstring[item]\n",
    "    text_with_breaks_processed = [\n",
    "        get_processed_token(token)\n",
    "        for token in text_with_breaks.split()\n",
    "        if token != 'LINEBREAK' and token != 'PARBREAK'\n",
    "    ]\n",
    "    assert recstring.split() == text_with_breaks_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = lambda lst: (x for x in lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile relevant information about a reading first, before aligning to recstring.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alignment_child = pd.read_csv('data/moby-passages-36/data-330-child/Alignment.csv', sep=',')\n",
    "session, sframe, nframes, word = df_alignment_child.session, df_alignment_child.sframe, df_alignment_child.nframes, df_alignment_child.word\n",
    "session, sframe, nframes, word = gen(session), gen(sframe), gen(nframes), gen(word)\n",
    "\n",
    "session_to_alignment = defaultdict(list)\n",
    "for session_id in session:\n",
    "    sframe_val, nframes_val, word_val = next(sframe), next(nframes), next(word)\n",
    "    if word_val[0] == '<':\n",
    "        word_val = '<pause>'\n",
    "    session_to_alignment[session_id].append([word_val, sframe_val, nframes_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $F_0$ information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f0_child = pd.read_csv('data/moby-passages-36/data-330-child/f0_184.csv', sep=',')\n",
    "df_f0_child.value = [[float(y.split(':')[0]) for y in x.split()] for x in df_f0_child.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "session, value = df_f0_child.session, df_f0_child.value\n",
    "session, value = gen(session), gen(value)\n",
    "session_to_f0 = {}\n",
    "for session_id in session:\n",
    "    session_to_f0[session_id] = next(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile into full data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CREATE_FEATURE_VECTOR(\n",
    "    token='',\n",
    "    matches_expected=0,\n",
    "    sframe=0,\n",
    "    nframes=0,\n",
    "    pitch_mean=0,\n",
    "    pitch_start=0,\n",
    "    pitch_end=0,\n",
    "    pitch_high=0,\n",
    "    pitch_low=0,\n",
    "    pitch_slope=0):\n",
    "    rv = {\n",
    "        'token': token,\n",
    "        'matches_expected': matches_expected,\n",
    "        'sframe': sframe,\n",
    "        'nframes': nframes,\n",
    "        'pitch_mean': pitch_mean,\n",
    "        'pitch_start': pitch_start,\n",
    "        'pitch_end': pitch_end,\n",
    "        'pitch_high': pitch_high,\n",
    "        'pitch_low': pitch_low,\n",
    "        'pitch_slope': pitch_slope\n",
    "    }\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_features = {}\n",
    "new_feature_names = [\n",
    "    'token',\n",
    "    'matches_expected'\n",
    "    'sframe',\n",
    "    'nframes',\n",
    "    'pitch_mean',\n",
    "    'pitch_start',\n",
    "    'pitch_end',\n",
    "    'pitch_high',\n",
    "    'pitch_low',\n",
    "    'pitch_slope'\n",
    "]\n",
    "\n",
    "for session, alignment in session_to_alignment.items():\n",
    "    recording_mean = sum(session_to_f0[session]) / len(session_to_f0[session])\n",
    "    session_to_features[session] = []\n",
    "    for token, sframe, nframes in alignment:\n",
    "        f0s = session_to_f0[session][sframe:sframe + nframes]\n",
    "        f0s = [x - recording_mean for x in f0s] # center\n",
    "        pitch_mean = sum(f0s) / len(f0s)\n",
    "        pitch_start = f0s[0]\n",
    "        pitch_end = f0s[-1]\n",
    "        pitch_high = max(f0s)\n",
    "        pitch_low = min(f0s)\n",
    "        pitch_slope = (pitch_end - pitch_start) / len(f0s)        \n",
    "        new_features = CREATE_FEATURE_VECTOR(\n",
    "            token=token,\n",
    "            sframe=sframe,\n",
    "            nframes=nframes,\n",
    "            pitch_mean=pitch_mean,\n",
    "            pitch_start=pitch_start,\n",
    "            pitch_end=pitch_end,\n",
    "            pitch_high=pitch_high,\n",
    "            pitch_low=pitch_low,\n",
    "            pitch_slope=pitch_slope\n",
    "        )\n",
    "        session_to_features[session].append(new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align readings with recstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pause>', 'sam', '<pause>', 'and', '<pause>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recstring_330_with_pauses = ('<pause> ' + ' <pause> '.join(item_number_to_recstring[330].split()) + ' <pause>').split()\n",
    "recstring_330_with_pauses[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the naive `diff` algorithm to align readings with recstrings. This method does not capture self-correcting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "differ = difflib.Differ()\n",
    "\n",
    "session_to_naive_alignment = {}\n",
    "for session, features in session_to_features.items():\n",
    "    transcribed_tokens = [x['token'] for x in features]\n",
    "    diff = differ.compare(transcribed_tokens, recstring_330_with_pauses)\n",
    "    \n",
    "    # remove '?' lines\n",
    "    diff = (x for x in list(diff) if x[0] != '?')\n",
    "    \n",
    "    # +: in full recstring but not in transcribed tokens (often, dummy <pause>s)\n",
    "    # -: in transcribed tokens but not in full recstring (child added words)\n",
    "    \n",
    "    naive_alignment = [[] for x in recstring_330_with_pauses]\n",
    "    for idx in range(len(naive_alignment)):\n",
    "        while True:\n",
    "            diff_next = next(diff)\n",
    "            if diff_next[0] == ' ':\n",
    "                naive_alignment[idx].append(diff_next[2:])\n",
    "                break\n",
    "            if diff_next[0] == '+':\n",
    "                break\n",
    "            \n",
    "            # diff_next[0] == '-'\n",
    "            naive_alignment[idx].append(diff_next[2:])\n",
    "    session_to_naive_alignment[session] = naive_alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what this naive alignment looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pause> ['<pause>']\n",
      "sam ['sam']\n",
      "<pause> []\n",
      "and ['and']\n",
      "<pause> []\n",
      "jo ['jo']\n",
      "<pause> ['<pause>']\n",
      "went ['went']\n",
      "<pause> []\n",
      "for ['for']\n",
      "<pause> ['<pause>']\n",
      "a ['a']\n",
      "<pause> []\n",
      "hike ['hike']\n",
      "<pause> ['<pause>']\n",
      "they ['they']\n",
      "<pause> ['<pause>']\n",
      "took ['took', 'a', 'path', '<pause>', 'through', 'the', 'woods', '<pause>', '<pause>', 'their', 'heads', '<pause>', '<pause>', '<pause>', 'through', 'the', '<pause>', '<pause>', 'they', 'took']\n",
      "<pause> ['<pause>']\n",
      "a ['a']\n",
      "<pause> ['<pause>']\n",
      "path ['path']\n",
      "<pause> ['<pause>']\n",
      "through ['through']\n",
      "<pause> ['<pause>']\n",
      "the ['their']\n",
      "<pause> ['<pause>']\n",
      "woods ['mother']\n",
      "<pause> []\n",
      "suddenly []\n",
      "<pause> []\n",
      "sam []\n",
      "<pause> ['<pause>']\n",
      "heard ['heard']\n",
      "<pause> []\n",
      "a ['a']\n",
      "<pause> []\n",
      "noise ['noise']\n",
      "<pause> []\n",
      "coming ['coming']\n",
      "<pause> ['<pause>']\n",
      "from ['from']\n",
      "<pause> []\n",
      "the ['the']\n",
      "<pause> []\n",
      "tree ['tree']\n",
      "<pause> ['<pause>']\n",
      "above ['above']\n",
      "<pause> ['<pause>']\n",
      "their ['their']\n",
      "<pause> []\n",
      "heads ['heads']\n",
      "<pause> []\n",
      "jo ['jo']\n",
      "<pause> []\n",
      "climbed []\n",
      "<pause> []\n",
      "up []\n",
      "<pause> []\n",
      "to []\n",
      "<pause> []\n",
      "see []\n",
      "<pause> ['<pause>']\n",
      "what ['what']\n",
      "<pause> ['<pause>']\n",
      "the ['the']\n",
      "<pause> ['<pause>']\n",
      "noise ['and', 'jo', 'went', '<pause>', 'for', 'a', '<pause>', 'hike', '<pause>', '<pause>', 'up', '<pause>', 'to', 'see', 'what', '<pause>', 'the', 'noise']\n",
      "<pause> ['<pause>']\n",
      "was ['was']\n",
      "<pause> ['<pause>']\n",
      "and ['and']\n",
      "<pause> ['<pause>']\n",
      "found ['found']\n",
      "<pause> []\n",
      "two ['two']\n",
      "<pause> []\n",
      "baby ['baby']\n",
      "<pause> []\n",
      "squirrels ['squirrels']\n",
      "<pause> ['<pause>']\n",
      "the ['the']\n",
      "<pause> []\n",
      "babies ['babies']\n",
      "<pause> []\n",
      "were ['were']\n",
      "<pause> []\n",
      "alone ['alone']\n",
      "<pause> ['<pause>']\n",
      "but ['but']\n",
      "<pause> []\n",
      "their ['their']\n",
      "<pause> ['<pause>']\n",
      "mother ['mother']\n",
      "<pause> ['<pause>']\n",
      "must ['must']\n",
      "<pause> []\n",
      "be ['be']\n",
      "<pause> []\n",
      "somewhere ['somewhere']\n",
      "<pause> []\n",
      "near ['near']\n",
      "<pause> ['<pause>']\n",
      "the ['the']\n",
      "<pause> ['<pause>']\n",
      "children ['children']\n",
      "<pause> ['<pause>']\n",
      "watched ['watched']\n",
      "<pause> []\n",
      "and ['and']\n",
      "<pause> []\n",
      "waited ['waited']\n",
      "<pause> ['<pause>']\n",
      "sure ['sure']\n",
      "<pause> []\n",
      "enough ['enough']\n",
      "<pause> []\n",
      "the ['the']\n",
      "<pause> []\n",
      "mother ['mother']\n",
      "<pause> []\n",
      "soon ['soon']\n",
      "<pause> []\n",
      "returned ['returned']\n",
      "<pause> ['<pause>']\n",
      "with ['with']\n",
      "<pause> ['<pause>']\n",
      "a ['a']\n",
      "<pause> []\n",
      "mouthful ['mouthful']\n",
      "<pause> []\n",
      "of ['of']\n",
      "<pause> []\n",
      "nuts ['nuts']\n",
      "<pause> ['<pause>']\n",
      "the ['the']\n",
      "<pause> ['<pause>']\n",
      "noises ['noises']\n",
      "<pause> ['<pause>']\n",
      "stopped ['<pause>', 'babies', '<pause>', 'stopped']\n",
      "<pause> ['<pause>']\n",
      "as ['as']\n",
      "<pause> []\n",
      "the ['the']\n",
      "<pause> []\n",
      "baby ['baby']\n",
      "<pause> []\n",
      "squirrels ['squirrels']\n",
      "<pause> []\n",
      "began ['began']\n",
      "<pause> []\n",
      "to ['to']\n",
      "<pause> ['<pause>']\n",
      "eat ['eat']\n",
      "<pause> ['<pause>']\n",
      "sam ['sam']\n",
      "<pause> ['<pause>']\n",
      "and ['and']\n",
      "<pause> ['<pause>']\n",
      "jo ['jo']\n",
      "<pause> []\n",
      "smiled ['smiled']\n",
      "<pause> []\n",
      "knowing ['knowing']\n",
      "<pause> ['<pause>']\n",
      "the ['the']\n",
      "<pause> []\n",
      "squirrels ['squirrels']\n",
      "<pause> []\n",
      "were ['were']\n",
      "<pause> ['safe', '<pause>', '<pause>']\n",
      "safe ['safe']\n",
      "<pause> ['<pause>']\n",
      "with ['with']\n",
      "<pause> []\n",
      "their ['their']\n",
      "<pause> ['<pause>']\n",
      "mother ['mother']\n",
      "<pause> ['<pause>']\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(recstring_330_with_pauses, session_to_naive_alignment[30908]):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we recompile the performance matrix based on this alignment. Note that:\n",
    "\n",
    "\n",
    "Also, add a flag if the token in the naive alignment matches the expected token in the recstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPIED FROM ABOVE:\n",
    "# features = {\n",
    "#     'token': token,\n",
    "#     'matches_expected': matches_expected,\n",
    "#     'sframe': sframe,\n",
    "#     'nframes': nframes,\n",
    "#     'pitch_mean': pitch_mean,\n",
    "#     'pitch_end': pitch_end,\n",
    "#     'pitch_high': pitch_high,\n",
    "#     'pitch_low': pitch_low,\n",
    "#     'pitch_slope': pitch_slope\n",
    "# }\n",
    "\n",
    "N_FEATURES = len(new_feature_names)\n",
    "\n",
    "new_compiled_features = {}\n",
    "for session, naive_alignment in session_to_naive_alignment.items():\n",
    "    features = session_to_features[session]\n",
    "    recompiled_features = []\n",
    "    previous_features_matrix_row_idx = 0\n",
    "    \n",
    "    for expected_token, aligned_token_group in zip(recstring_330_with_pauses, naive_alignment):\n",
    "        if aligned_token_group == []:\n",
    "            recompiled_features.append(CREATE_FEATURE_VECTOR(matches_expected=0))\n",
    "            continue\n",
    "        if len(aligned_token_group) == 1:\n",
    "            is_correct_token = 1 if aligned_token_group[0] == expected_token else 0\n",
    "            old_features = features[previous_features_matrix_row_idx]\n",
    "            old_features['matches_expected'] = is_correct_token\n",
    "            recompiled_features.append(old_features)\n",
    "            previous_features_matrix_row_idx += 1\n",
    "        else:\n",
    "            # multiple tokens\n",
    "            num_tokens = len(aligned_token_group)\n",
    "            features_for_token_group = [features[i] for i in range(previous_features_matrix_row_idx, previous_features_matrix_row_idx + num_tokens)]\n",
    "            \n",
    "            '''\n",
    "            Now compile new features\n",
    "            '''\n",
    "            last_token_in_token_group = aligned_token_group[-1]\n",
    "            features_for_last_token = features_for_token_group[-1]\n",
    "            if last_token_in_token_group == expected_token:\n",
    "                token = expected_token\n",
    "            else:\n",
    "                token = ' '.join(aligned_token_group)\n",
    "            sframe = features_for_token_group[0]['sframe'] # sframe for updated feature is the sframe for the first token in the aligned token group\n",
    "            nframes = sum(f['nframes'] for f in features_for_token_group)\n",
    "            \n",
    "            # pitch-related features can match that of the last token, even if it is not the expected token\n",
    "            pitch_mean = features_for_last_token['pitch_mean']\n",
    "            pitch_start = features_for_last_token['pitch_start']\n",
    "            pitch_end = features_for_last_token['pitch_end']\n",
    "            pitch_high = features_for_last_token['pitch_high']\n",
    "            pitch_low = features_for_last_token['pitch_low']\n",
    "            pitch_slope = features_for_last_token['pitch_slope']\n",
    "            \n",
    "            new_feature_to_add = CREATE_FEATURE_VECTOR(\n",
    "                token=token,\n",
    "                matches_expected=0,\n",
    "                sframe=sframe,\n",
    "                nframes=nframes,\n",
    "                pitch_mean=pitch_mean,\n",
    "                pitch_start=pitch_start,\n",
    "                pitch_end=pitch_end,\n",
    "                pitch_high=pitch_high,\n",
    "                pitch_low=pitch_low,\n",
    "                pitch_slope=pitch_slope\n",
    "            )\n",
    "            recompiled_features.append(new_feature_to_add)\n",
    "            previous_features_matrix_row_idx += num_tokens\n",
    "    new_compiled_features[session] = recompiled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME_PREFIX = '20190720_child_readings_'\n",
    "\n",
    "for session, features in new_compiled_features.items():\n",
    "    matrix = pd.DataFrame(features)\n",
    "    matrix.index = recstring_330_with_pauses\n",
    "    matrix.to_csv('output/performance_matrix/' + FILENAME_PREFIX + str(session) + '.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
