{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling performance matrix\n",
    "\n",
    "This notebook should be self-contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, string, difflib\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from better_align_util import get_before_util, get_after_util, better_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "\n",
    "PASSAGE_WITH_LINE_BREAK_AND_RECSTRING = 'data/moby-passages-36/passages-with-line-break-and-recstring.tsv'\n",
    "PASSAGES_WITH_LINE_BREAKS = 'data/moby-passages-36/passages-with-line-breaks.tsv'\n",
    "\n",
    "####\n",
    "ITEM_NUMBER = 330\n",
    "ALIGNMENT = 'data/moby-passages-36/data-330-gold/AlignedWords.csv'\n",
    "F0 = 'data/moby-passages-36/data-330-gold/F0s.csv'\n",
    "####\n",
    "\n",
    "# Output\n",
    "\n",
    "OUTPUT_DIR = 'output/performance_matrix/330_gold_updated_20200729/'\n",
    "FILENAME_PREFIX = OUTPUT_DIR + ''\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For each item, load recstring and token-by-token representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_texts_and_recstrings = pd.read_csv(PASSAGE_WITH_LINE_BREAK_AND_RECSTRING, sep='\\t')\n",
    "item_number_to_recstring = dict(zip(df_full_texts_and_recstrings.Item, df_full_texts_and_recstrings['Rec String']))\n",
    "df_text_with_line_breaks = pd.read_csv(PASSAGES_WITH_LINE_BREAKS, sep='\\t', names=['Item', 'Passage'])\n",
    "item_number_to_text_with_line_breaks = dict(zip(df_text_with_line_breaks.Item, df_text_with_line_breaks.Passage))\n",
    "item_number_to_text_with_line_breaks = {\n",
    "    k: v[:v.index('#')].replace('$$', ' PARBREAK ').replace('$', ' LINEBREAK ').replace(' 45 ', ' forty five ')\n",
    "    for k, v in item_number_to_text_with_line_breaks.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check that the token-by-token representation minus line/paragraph breaks matches the recstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sam and Jo went for a hike. They took a path through the  LINEBREAK woods. Suddenly, Sam heard a noise coming from the tree  LINEBREAK above their heads. Jo climbed up to see what the noise was  LINEBREAK and found two baby squirrels. The babies were alone, but  LINEBREAK their mother must be somewhere near. The children watched  LINEBREAK and waited. PARBREAK Sure enough, the mother soon returned with a mouthful of nuts.  LINEBREAK The noises stopped as the baby squirrels began to eat. PARBREAK Sam and Jo smiled, knowing the squirrels were safe with  LINEBREAK their mother.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_number_to_text_with_line_breaks[ITEM_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_token(token):\n",
    "    rv = token\n",
    "    while rv[0] in string.punctuation:\n",
    "        rv = rv[1:]\n",
    "    while rv[-1] in string.punctuation:\n",
    "        rv = rv[:-1]\n",
    "    return rv.lower()\n",
    "\n",
    "for item, text_with_breaks in item_number_to_text_with_line_breaks.items():\n",
    "    recstring = item_number_to_recstring[item]\n",
    "    text_with_breaks_processed = [\n",
    "        get_processed_token(token)\n",
    "        for token in text_with_breaks.split()\n",
    "        if token != 'LINEBREAK' and token != 'PARBREAK'\n",
    "    ]\n",
    "    assert recstring.split() == text_with_breaks_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = lambda lst: (x for x in lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile relevant information about a reading first, before aligning to recstring.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alignment_child = pd.read_csv(ALIGNMENT, sep=',')\n",
    "session, sframe, nframes, word = df_alignment_child.session, df_alignment_child.sframe, df_alignment_child.nframes, df_alignment_child.word\n",
    "session, sframe, nframes, word = gen(session), gen(sframe), gen(nframes), gen(word)\n",
    "\n",
    "session_to_alignment = defaultdict(list)\n",
    "for session_id in session:\n",
    "    sframe_val, nframes_val, word_val = next(sframe), next(nframes), next(word)\n",
    "    if word_val[0] == '<':\n",
    "        word_val = '<pause>'\n",
    "    session_to_alignment[session_id].append([word_val, sframe_val, nframes_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $F_0$ information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f0_child = pd.read_csv(F0, sep=',')\n",
    "df_f0_child.value = [[float(y.split(':')[0]) for y in x.split()] for x in df_f0_child.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "session, value = df_f0_child.session, df_f0_child.value\n",
    "session, value = gen(session), gen(value)\n",
    "session_to_f0 = {}\n",
    "for session_id in session:\n",
    "    session_to_f0[session_id] = next(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile into full data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CREATE_FEATURE_VECTOR(\n",
    "    token='',\n",
    "    matches_expected=0,\n",
    "    sframe=0,\n",
    "    nframes=0,\n",
    "    pitch_mean=0,\n",
    "    pitch_start=0,\n",
    "    pitch_end=0,\n",
    "    pitch_high=0,\n",
    "    pitch_low=0,\n",
    "    pitch_slope=0):\n",
    "    rv = {\n",
    "        'token': token,\n",
    "        'matches_expected': matches_expected,\n",
    "        'sframe': sframe,\n",
    "        'nframes': nframes,\n",
    "        'pitch_mean': pitch_mean,\n",
    "        'pitch_start': pitch_start,\n",
    "        'pitch_end': pitch_end,\n",
    "        'pitch_high': pitch_high,\n",
    "        'pitch_low': pitch_low,\n",
    "        'pitch_slope': pitch_slope\n",
    "    }\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_features = {}\n",
    "new_feature_names = [\n",
    "    'token',\n",
    "    'matches_expected'\n",
    "    'sframe',\n",
    "    'nframes',\n",
    "    'pitch_mean',\n",
    "    'pitch_start',\n",
    "    'pitch_end',\n",
    "    'pitch_high',\n",
    "    'pitch_low',\n",
    "    'pitch_slope'\n",
    "]\n",
    "\n",
    "for session, alignment in session_to_alignment.items():\n",
    "    recording_mean = sum(session_to_f0[session]) / len(session_to_f0[session])\n",
    "    session_to_features[session] = []\n",
    "    for token, sframe, nframes in alignment:\n",
    "        f0s = session_to_f0[session][sframe:sframe + nframes]\n",
    "        f0s = [x - recording_mean for x in f0s] # center\n",
    "        pitch_mean = sum(f0s) / len(f0s)\n",
    "        pitch_start = f0s[0]\n",
    "        pitch_end = f0s[-1]\n",
    "        pitch_high = max(f0s)\n",
    "        pitch_low = min(f0s)\n",
    "        pitch_slope = (pitch_end - pitch_start) / len(f0s)        \n",
    "        new_features = CREATE_FEATURE_VECTOR(\n",
    "            token=token,\n",
    "            sframe=sframe,\n",
    "            nframes=nframes,\n",
    "            pitch_mean=pitch_mean,\n",
    "            pitch_start=pitch_start,\n",
    "            pitch_end=pitch_end,\n",
    "            pitch_high=pitch_high,\n",
    "            pitch_low=pitch_low,\n",
    "            pitch_slope=pitch_slope\n",
    "        )\n",
    "        session_to_features[session].append(new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align readings with recstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pause>', 'sam', '<pause>', 'and', '<pause>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recstring_330_with_pauses = ('<pause> ' + ' <pause> '.join(item_number_to_recstring[ITEM_NUMBER].split()) + ' <pause>').split()\n",
    "recstring_330_with_pauses[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the naive `diff` algorithm to align readings with recstrings. This method does not capture self-correcting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "differ = difflib.Differ()\n",
    "\n",
    "session_to_naive_alignment = {}\n",
    "for session, features in session_to_features.items():\n",
    "    transcribed_tokens = [x['token'] for x in features]\n",
    "    diff = differ.compare(transcribed_tokens, recstring_330_with_pauses)\n",
    "    \n",
    "    # remove '?' lines\n",
    "    diff = (x for x in list(diff) if x[0] != '?')\n",
    "    \n",
    "    # +: in full recstring but not in transcribed tokens (often, dummy <pause>s)\n",
    "    # -: in transcribed tokens but not in full recstring (child added words)\n",
    "    \n",
    "    naive_alignment = [[] for x in recstring_330_with_pauses]\n",
    "    for idx in range(len(naive_alignment)):\n",
    "        while True:\n",
    "            diff_next = next(diff)\n",
    "            if diff_next[0] == ' ':\n",
    "                naive_alignment[idx].append(diff_next[2:])\n",
    "                break\n",
    "            if diff_next[0] == '+':\n",
    "                break\n",
    "            \n",
    "            # diff_next[0] == '-'\n",
    "            naive_alignment[idx].append(diff_next[2:])\n",
    "    session_to_naive_alignment[session] = naive_alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Kludge: add meaningless pause to beginning and end, if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_features_added_pause = {}\n",
    "for session, features in session_to_features.items():\n",
    "    tokens = [x['token'] for x in features]\n",
    "    if tokens[-1] != '<pause>':\n",
    "        features.append(CREATE_FEATURE_VECTOR(token='<pause>'))\n",
    "    if token[0] != '<pause>':\n",
    "        features.insert(0, CREATE_FEATURE_VECTOR(token='<pause>'))\n",
    "    session_to_features_added_pause[session] = features\n",
    "session_to_features = session_to_features_added_pause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_naive_alignment = {}\n",
    "for session, features in session_to_features.items():\n",
    "    transcribed_tokens = [x['token'] for x in features]\n",
    "    try:\n",
    "        session_to_naive_alignment[session] = better_align(transcribed_tokens, recstring_330_with_pauses)\n",
    "    except:\n",
    "        print('Failed at session', session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we recompile the performance matrix based on this alignment. Note that:\n",
    "\n",
    "\n",
    "Also, add a flag if the token in the naive alignment matches the expected token in the recstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPIED FROM ABOVE:\n",
    "# features = {\n",
    "#     'token': token,\n",
    "#     'matches_expected': matches_expected,\n",
    "#     'sframe': sframe,\n",
    "#     'nframes': nframes,\n",
    "#     'pitch_mean': pitch_mean,\n",
    "#     'pitch_end': pitch_end,\n",
    "#     'pitch_high': pitch_high,\n",
    "#     'pitch_low': pitch_low,\n",
    "#     'pitch_slope': pitch_slope\n",
    "# }\n",
    "\n",
    "N_FEATURES = len(new_feature_names)\n",
    "\n",
    "new_compiled_features = {}\n",
    "for session, naive_alignment in session_to_naive_alignment.items():\n",
    "    features = session_to_features[session]\n",
    "    recompiled_features = []\n",
    "    previous_features_matrix_row_idx = 0\n",
    "    \n",
    "    for expected_token, aligned_token_group in zip(recstring_330_with_pauses, naive_alignment):\n",
    "        if aligned_token_group == []:\n",
    "            recompiled_features.append(CREATE_FEATURE_VECTOR(matches_expected=0))\n",
    "            continue\n",
    "        if len(aligned_token_group) == 1:\n",
    "            is_correct_token = 1 if aligned_token_group[0] == expected_token else 0\n",
    "            old_features = features[previous_features_matrix_row_idx]\n",
    "            old_features['matches_expected'] = is_correct_token\n",
    "            recompiled_features.append(old_features)\n",
    "            previous_features_matrix_row_idx += 1\n",
    "        else:\n",
    "            # multiple tokens\n",
    "            num_tokens = len(aligned_token_group)\n",
    "            features_for_token_group = [features[i] for i in range(previous_features_matrix_row_idx, previous_features_matrix_row_idx + num_tokens)]\n",
    "            \n",
    "            '''\n",
    "            Now compile new features\n",
    "            '''\n",
    "            last_token_in_token_group = aligned_token_group[-1]\n",
    "            features_for_last_token = features_for_token_group[-1]\n",
    "            if last_token_in_token_group == expected_token:\n",
    "                token = expected_token\n",
    "            else:\n",
    "                token = ' '.join(aligned_token_group)\n",
    "            sframe = features_for_token_group[0]['sframe'] # sframe for updated feature is the sframe for the first token in the aligned token group\n",
    "            nframes = sum(f['nframes'] for f in features_for_token_group)\n",
    "            \n",
    "            # pitch-related features can match that of the last token, even if it is not the expected token\n",
    "            pitch_mean = features_for_last_token['pitch_mean']\n",
    "            pitch_start = features_for_last_token['pitch_start']\n",
    "            pitch_end = features_for_last_token['pitch_end']\n",
    "            pitch_high = features_for_last_token['pitch_high']\n",
    "            pitch_low = features_for_last_token['pitch_low']\n",
    "            pitch_slope = features_for_last_token['pitch_slope']\n",
    "            \n",
    "            new_feature_to_add = CREATE_FEATURE_VECTOR(\n",
    "                token=token,\n",
    "                matches_expected=0,\n",
    "                sframe=sframe,\n",
    "                nframes=nframes,\n",
    "                pitch_mean=pitch_mean,\n",
    "                pitch_start=pitch_start,\n",
    "                pitch_end=pitch_end,\n",
    "                pitch_high=pitch_high,\n",
    "                pitch_low=pitch_low,\n",
    "                pitch_slope=pitch_slope\n",
    "            )\n",
    "            recompiled_features.append(new_feature_to_add)\n",
    "            previous_features_matrix_row_idx += num_tokens\n",
    "    new_compiled_features[session] = recompiled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session, features in new_compiled_features.items():\n",
    "    matrix = pd.DataFrame(features)\n",
    "    matrix.index = recstring_330_with_pauses\n",
    "    matrix.to_csv(FILENAME_PREFIX + str(session) + '.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
