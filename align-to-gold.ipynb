{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aligning constituency parse to gold reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6/30/20\n",
    "\n",
    "Okay, so for the moment the only reason we are concerned with a constituency parse is because we want to extract **phrases** from passages.\n",
    "\n",
    "Constituency parsing offered by accurate, easy-to-use parsers end up parsing the passages in a format that isn't exactly compatible with our alignments. The differences include:\n",
    "\n",
    "- Constituency parsing splits contractions, while forced alignments are a word-by-word.\n",
    "- Constituency parsing preserves punctuation (minor difference)\n",
    "- Forced alignments contain **pauses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ycm/opt/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "from benepar.spacy_plugin import BeneparComponent\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(BeneparComponent('benepar_en'))\n",
    "doc = nlp(\"Sam and Jo went for a hike. They took a path through the woods. Suddenly, Sam heard a noise coming from the tree above their heads. Jo climbed up to see what the noise was, and found two baby squirrels. The babies were alone, but their mother must be somewhere near. The children watched and waited. Sure enough, the mother soon returned with a mouthful of nuts. The noises stopped as the baby squirrels began to eat. Sam and Jo smiled, knowing the squirrels were safe with their mother.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "1. Remove pauses from gold readings somehow. Then all the gold readings should have the same words\n",
    "\n",
    "2. Align **constituency parse** to one of the gold readings. Punctuation tokens will have to be dropped, and contractions will have to be dealt with at a later time. (Item 330 has no contractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing pauses.\n",
    "\n",
    "I join the duration of all pauses into the next word, but for the time being this is irrelevant. I'm just trying to get only the **words** to create a *transcript*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/raw/align.json') as f:\n",
    "    raw_align = json.load(f)\n",
    "rv = {}\n",
    "for sess, alignment in raw_align.items():\n",
    "    no_pauses = []\n",
    "    curr_nframes = 0\n",
    "    for token, sframe, nframes in alignment:\n",
    "        if token[0] != '<':\n",
    "            no_pauses.append([token, curr_nframes + nframes])\n",
    "            curr_nframes = 0\n",
    "        else:\n",
    "            curr_nframes += nframes\n",
    "    rv[sess] = no_pauses\n",
    "align_no_pause = {sess: rv[sess] for sess in rv if len(rv[sess]) == 89}\n",
    "# with open('data/raw/align-no-pause.json', 'w') as f:\n",
    "#     json.dump(align_no_pause, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Align constituency parse to a gold reading\n",
    "\n",
    "Each token in the constituency parse (incl. punctuation and sub-words) has an associated *index*. I match each token to its correponding index in the gold readings, if possible. So tokens like punctuation don't get assigned, but that's okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align_no_pause['54344']\n",
    "gold_tokens = [xy[0] for xy in align_no_pause['54344']]\n",
    "idxs = [token.i for token in doc if str(token) not in {'.', ',', '?'}]\n",
    "doc_idx_to_align_idx = dict(zip(idxs, range(len(gold_tokens))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect sentence indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "sam and jo went for a hike\n",
      "[7, 8, 9, 10, 11, 12, 13]\n",
      "they took a path through the woods\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "suddenly sam heard a noise coming from the tree above their heads\n",
      "[26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "jo climbed up to see what the noise was and found two baby squirrels\n",
      "[40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
      "the babies were alone but their mother must be somewhere near\n",
      "[51, 52, 53, 54, 55]\n",
      "the children watched and waited\n",
      "[56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66]\n",
      "sure enough the mother soon returned with a mouthful of nuts\n",
      "[67, 68, 69, 70, 71, 72, 73, 74, 75, 76]\n",
      "the noises stopped as the baby squirrels began to eat\n",
      "[77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88]\n",
      "sam and jo smiled knowing the squirrels were safe with their mother\n"
     ]
    }
   ],
   "source": [
    "STRUCTURE_sentences = []\n",
    "for sent in doc.sents:\n",
    "    sent_indexed = [doc_idx_to_align_idx[token.i] for token in sent if token.i in doc_idx_to_align_idx]\n",
    "    print(sent_indexed)\n",
    "    print(' '.join(gold_tokens[idx] for idx in sent_indexed))\n",
    "    STRUCTURE_sentences.append(sent_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect phrase indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_children(span, sent_num, STRUCTURE_phrases, level):\n",
    "    children = list(span._.children)\n",
    "    for child in children:\n",
    "        TAG = child._.labels[0] if child._.labels else None\n",
    "        token_indices = [token.i for token in child]\n",
    "        # No leaf nodes and no trivial parents\n",
    "        if TAG and len(token_indices) > 1:\n",
    "            STRUCTURE_phrases[sent_num].append([\n",
    "                level,\n",
    "                TAG,\n",
    "                token_indices\n",
    "            ])\n",
    "        print_children(child, sent_num, STRUCTURE_phrases, level + 1)\n",
    "\n",
    "sents = list(doc.sents)\n",
    "STRUCTURE_phrases = [[] for _ in range(len(sents))]\n",
    "for sent_num, sent in enumerate(sents):\n",
    "    print_children(sent, sent_num, STRUCTURE_phrases, level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo: Sentence **3**, depth **2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\tto see what the noise was\n",
      "NP\ttwo baby squirrels\n"
     ]
    }
   ],
   "source": [
    "demo = [value for value in STRUCTURE_phrases[3] if value[0] == 2]\n",
    "\n",
    "for _, TAG, TOKEN_IDS in demo:\n",
    "    print(TAG + '\\t' + ' '.join([gold_tokens[doc_idx_to_align_idx[idx]] for idx in TOKEN_IDS]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='misc/fig-parse-tree-depth-nodes.png' width='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo: Sentence **3**, all **NP**s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP\tthe noise\n",
      "NP\ttwo baby squirrels\n"
     ]
    }
   ],
   "source": [
    "demo = [value for value in STRUCTURE_phrases[3] if value[1] == 'NP']\n",
    "for _, TAG, TOKEN_IDS in demo:\n",
    "    print(TAG + '\\t' + ' '.join([gold_tokens[doc_idx_to_align_idx[idx]] for idx in TOKEN_IDS]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='misc/fig-parse-tree-np-nodes.png' width='600'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
